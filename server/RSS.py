# coding=windows-1251

"""
--- ѕростой RSS reader ---
    ѕри добавлении ленты (например https://habrahabr.ru/rss/interesting/)
записи из добавленной ленты сканируютс€ и занос€тс€ в базу (например sqlite)
    ѕри нажатии на кнопку обновить - новое сканирование и добавление новых записей (без дублровани€ существующих)
    ќтображение ленты начина€ с самых свежих записей с пагинацией (несколько записей на странице)
    «аписи из разных лент хранить и показывать отдельно (по названию ленты).
    ¬нимание:
ѕосле сдачи и визировани€ отчета принести его на лекцию (за 5 мин до начала)
+ ѕродублировать отчет и исходник(.zip, github и т.п.) письмом на isu
"""

import feedparser
import psycopg2 as db
from psycopg2 import sql
from contextlib import closing
import os

FEEDS = [
    {'name': 'bbci', 'link': 'http://feeds.bbci.co.uk/news/world/rss.xml'},
    {'name': 'NewYorkTimes',
     'link': 'https://www.nytimes.com/svc/collections/v1/publish/https://www.nytimes.com/section/world/rss.xml'},
    {'name': 'habr', 'link': 'https://habrahabr.ru/rss/interesting/'},
    {'name': 'BuzzFeed',
     'link': 'https://www.buzzfeed.com/world.xml'}
]


def rss_parser(feed_name: str) -> [{}]:
    link = None
    for row in FEEDS:
        if row.get('name') == feed_name:
            link = row.get('link')
            print(link)
    News = feedparser.parse(link)
    return News.entries


def write_to_db(news_feed_name):
    arr = rss_parser(news_feed_name)
    with closing(db.connect(database="postgres",
                            user=os.getenv('db_user'),
                            password=os.getenv('db_pswd'),
                            host="127.0.0.1",
                            port="5433")) as conn:
        with conn.cursor() as cursor:
            print('--- db open successfully')
            conn.autocommit = True
            """ get all existed title for selected feed name """
            existed_titles = []
            cursor.execute(f'SELECT link FROM python_rss.news WHERE news_feed_name = \'{news_feed_name}\'')
            for row in cursor:
                existed_titles.append(row[0])

            values = []
            """ check if title existed and execute 'insert' """
            for next_article in arr:
                if next_article.get('id') not in existed_titles:
                    values.append((news_feed_name, next_article.get('title'), next_article.get('published'),
                                   next_article.get('id')))
            if len(values) > 0:
                print(f'{len(values)} objects will be stored')
                insert = sql.SQL('INSERT INTO python_rss.news (news_feed_name, title, date, link) VALUES {}').format(
                    sql.SQL(',').join(map(sql.Literal, values))
                )
                cursor.execute(insert)
            print('--- db close successfully')


def get_all_news_by_feed(feed_name: str) -> []:
    with closing(db.connect(database="postgres",
                            user=os.getenv('db_user'),
                            password=os.getenv('db_pswd'),
                            host="127.0.0.1",
                            port="5433")) as conn:
        with conn.cursor() as cursor:
            conn.autocommit = True
            cursor.execute(f'SELECT * FROM python_rss.news WHERE news_feed_name = \'{feed_name}\'')
            news = []
            for row in cursor:
                news.append(row)
            return news


def get_news_feed_name(link: str) -> str:
    start_index = link.index('//') + 2
    end_index = link.index('.')
    return link[start_index:end_index]


def get_feeds() -> []:
    return FEEDS


def init_feeds():
    print(FEEDS)


def add_feed(name: str, link: str) -> None:
    FEEDS.append({"name": name, "link": link})
    print(FEEDS)
